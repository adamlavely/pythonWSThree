{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding Up I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I/O is one of the most time-intensive things we do in any coding language - let's explore some ways to do this more efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used numpy's loadtxt and genfromtxt in October's sessions - these are fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.] [ 10.  21.  32.  43.  54.  65.  76.  87.  98. 109.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "firstColFlt, secColFlt = np.loadtxt( \"random.txt\", dtype=float, usecols=[0,1], unpack=True )\n",
    "print firstColFlt, secColFlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy can save multiple arrays in a binary format with savez, but watch the ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_1', 'arr_0']\n",
      "[ 10.  21.  32.  43.  54.  65.  76.  87.  98. 109.]\n"
     ]
    }
   ],
   "source": [
    "np.savez('binaryNonCompressed.npz', firstColFlt, secColFlt)\n",
    "npzFile = np.load('binaryNonCompressed.npz')\n",
    "print npzFile.files\n",
    "print npzFile['arr_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also has a way to compress the binary data - this is slower (time for compression and decompresssion) but may be beneficial if you are moving data between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_1', 'arr_0']\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "np.savez_compressed('binaryCompressed.npz', firstColFlt, secColFlt)\n",
    "npzCFile = np.load('binaryCompressed.npz')\n",
    "print npzCFile.files\n",
    "print npzCFile['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary reads and writes will always be faster than ascii.  Read your data in the original form one time and save it in a much better form for reading subsequent times. The python pickle package allows for very efficient I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "\n",
    "pk.dump(firstColFlt, open( \"firstCol.pkl\", \"wb\"))\n",
    "readInFirstCol = pk.load( open( \"firstCol.pkl\", \"rb\"))\n",
    "print readInFirstCol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python2 has cPickle which is considerably faster for large data dumps and reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.  21.  32.  43.  54.  65.  76.  87.  98. 109.]\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pk\n",
    "\n",
    "pk.dump(secColFlt, open( \"secCol.pkl\", \"wb\"))\n",
    "readInSecCol = pk.load( open( \"secCol.pkl\", \"rb\"))\n",
    "print readInSecCol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have the same modes as with standard python files (w and r), but are also doing binary (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has read_csv, as well as some specialized I/O methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names  Score  Unnamed: 2\n",
      "0  Billy     98         NaN\n",
      "1   Joel     95         NaN\n",
      "2  Elton     96         NaN\n",
      "3   John     85         NaN\n",
      "4  James     92         NaN\n",
      "5   Earl     91         NaN\n",
      "6  Jones     88         NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "testFrame = pd.read_csv( 'testScores.csv' )\n",
    "print testFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is an extra, unnamed column with NaNs because each line ends with a \",\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a built in method to store data using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names  Score\n",
      "0  Billy     98\n",
      "1   Joel     95\n",
      "2  Elton     96\n",
      "3   John     85\n",
      "4  James     92\n",
      "5   Earl     91\n",
      "6  Jones     88\n"
     ]
    }
   ],
   "source": [
    "noUnnamedFrame = testFrame.drop( columns = \"Unnamed: 2\" )\n",
    "noUnnamedFrame.to_pickle( 'testFrame.pkl' )\n",
    "readFrame = pd.read_pickle( 'testFrame.pkl' )\n",
    "print readFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has the ability to use hdf5, which can be coupled to many other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names\n",
      "0  Billy\n",
      "1   Joel\n",
      "2  Elton\n",
      "3   John\n",
      "4  James\n",
      "5   Earl\n",
      "6  Jones\n"
     ]
    }
   ],
   "source": [
    "namesFrame = noUnnamedFrame.drop( columns = \"Score\" )\n",
    "hdf5File =  pd.HDFStore( 'storeFrame.h5' )\n",
    "hdf5File['namesFrame'] = namesFrame\n",
    "readInNames = hdf5File['namesFrame']\n",
    "print readInNames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
